<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>DevOps on Funky Si's Blog</title><link>https://www.funkysi1701.com/tags/devops/</link><description>Recent content in DevOps on Funky Si's Blog</description><generator>Hugo -- gohugo.io</generator><language>en-gb</language><lastBuildDate>Mon, 10 Jan 2022 20:00:45 +0000</lastBuildDate><atom:link href="https://www.funkysi1701.com/tags/devops/index.xml" rel="self" type="application/rss+xml"/><item><title>Using GitHub Actions</title><link>https://www.funkysi1701.com/posts/2022/using-github-actions/</link><pubDate>Mon, 10 Jan 2022 20:00:45 +0000</pubDate><guid>https://www.funkysi1701.com/posts/2022/using-github-actions/</guid><description>&lt;p>I&amp;rsquo;ve been running my website on Azure Static Web Apps for a while and it is pretty cool.&lt;/p>
&lt;p>When you create a Static Web App on Azure you get asked for the github repo of your source code and even the branch to use.
&lt;img class="img-fluid" alt="GitHub Repo for my Static Web App" src="https://dev-to-uploads.s3.amazonaws.com/uploads/articles/off7ur2tgsla4smkrhhi.png" loading="lazy"
/>
&lt;/p>
&lt;p>Once you have selected this, you get asked for the type of code to deploy, mine is Blazor Web Assembly but you can use Angular, React or Vue.&lt;/p>
&lt;p>&lt;img class="img-fluid" alt="GitHub Actions workflow creation" src="https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ruhzjeujgl1yjxx5lng8.png" loading="lazy"
/>
You now have three variables to fill in the location in your code of the Website, the location of your Azure Functions and the output location usually wwwroot. Once you have set these three you can preview the GitHub Actions file that will be created and added to your repository.&lt;/p>
&lt;p>I get something like this&lt;/p>
&lt;pre tabindex="0">&lt;code>name: Azure Static Web Apps CI/CD
on:
push:
branches:
- feature/tempbranch
pull_request:
types: [opened, synchronize, reopened, closed]
branches:
- feature/tempbranch
jobs:
build_and_deploy_job:
if: github.event_name == &amp;#39;push&amp;#39; || (github.event_name == &amp;#39;pull_request&amp;#39; &amp;amp;&amp;amp; github.event.action != &amp;#39;closed&amp;#39;)
runs-on: ubuntu-latest
name: Build and Deploy Job
steps:
- uses: actions/checkout@v2
with:
submodules: true
- name: Build And Deploy
id: builddeploy
uses: Azure/static-web-apps-deploy@v1
with:
azure_static_web_apps_api_token: ${{ secrets.AZURE_STATIC_WEB_APPS_API_TOKEN_&amp;lt;GENERATED_HOSTNAME&amp;gt; }}
repo_token: ${{ secrets.GITHUB_TOKEN }} # Used for Github integrations (i.e. PR comments)
action: &amp;#34;upload&amp;#34;
###### Repository/Build Configurations - These values can be configured to match your app requirements. ######
# For more information regarding Static Web App workflow configurations, please visit: https://aka.ms/swaworkflowconfig
app_location: &amp;#34;Client&amp;#34; # App source code path
api_location: &amp;#34;Api&amp;#34; # Api source code path - optional
output_location: &amp;#34;wwwroot&amp;#34; # Built app content directory - optional
###### End of Repository/Build Configurations ######
close_pull_request_job:
if: github.event_name == &amp;#39;pull_request&amp;#39; &amp;amp;&amp;amp; github.event.action == &amp;#39;closed&amp;#39;
runs-on: ubuntu-latest
name: Close Pull Request Job
steps:
- name: Close Pull Request
id: closepullrequest
uses: Azure/static-web-apps-deploy@v1
with:
azure_static_web_apps_api_token: ${{ secrets.AZURE_STATIC_WEB_APPS_API_TOKEN_&amp;lt;GENERATED_HOSTNAME&amp;gt; }}
action: &amp;#34;close&amp;#34;
&lt;/code>&lt;/pre>&lt;p>This github action will run when you create a Pull Request to the branch mentioned in the file, or if you push code into the branch. This code get added into the .github/workflows/ folder and is the location that all github action workflows live.&lt;/p>
&lt;p>I haven&amp;rsquo;t done much with github actions, however I have used Azure DevOps quite a bit. Over on the Azure DevOps side I have created a pipeline that deploys to a Dev environment, then a Test environment and finally a production environment.&lt;/p>
&lt;p>Lets have a look at the workflow that I ended up with and with can break down how it all works. Note I am new to Github actions so if there is a better way of doing this do let me know.&lt;/p>
&lt;pre tabindex="0">&lt;code>name: Azure Static Web Apps
on:
push:
branches:
- main
- develop
- feature/*
jobs:
dev:
runs-on: ubuntu-latest
environment:
name: Dev
name: Dev
steps:
- uses: actions/checkout@v2
with:
submodules: true
- name: Build And Deploy
id: builddeploy
uses: Azure/static-web-apps-deploy@v1
with:
azure_static_web_apps_api_token: ${{ secrets.AZURE_STATIC_WEB_APPS_API_TOKEN_ORANGE_POND_09B18B903 }}
repo_token: ${{ secrets.GITHUB_TOKEN }} # Used for Github integrations (i.e. PR comments)
action: &amp;#34;upload&amp;#34;
###### Repository/Build Configurations - These values can be configured to match your app requirements. ######
# For more information regarding Static Web App workflow configurations, please visit: https://aka.ms/swaworkflowconfig
app_location: &amp;#34;Blog&amp;#34; # App source code path
api_location: &amp;#34;Blog.Func&amp;#34; # Api source code path - optional
output_location: &amp;#34;wwwroot&amp;#34; # Built app content directory - optional
###### End of Repository/Build Configurations ######
test:
if: github.ref == &amp;#39;refs/heads/develop&amp;#39;
runs-on: ubuntu-latest
environment:
name: Test
name: Test
steps:
- uses: actions/checkout@v2
with:
submodules: true
- name: Build And Deploy
id: builddeploy
uses: Azure/static-web-apps-deploy@v1
with:
azure_static_web_apps_api_token: ${{ secrets.AZURE_STATIC_WEB_APPS_API_TOKEN_WITTY_DUNE_0A1A77903 }}
repo_token: ${{ secrets.GITHUB_TOKEN }} # Used for Github integrations (i.e. PR comments)
action: &amp;#34;upload&amp;#34;
###### Repository/Build Configurations - These values can be configured to match your app requirements. ######
# For more information regarding Static Web App workflow configurations, please visit: https://aka.ms/swaworkflowconfig
app_location: &amp;#34;Blog&amp;#34; # App source code path
api_location: &amp;#34;Blog.Func&amp;#34; # Api source code path - optional
output_location: &amp;#34;wwwroot&amp;#34; # Built app content directory - optional
###### End of Repository/Build Configurations ######
prod:
if: github.ref == &amp;#39;refs/heads/main&amp;#39;
runs-on: ubuntu-latest
environment:
name: Prod
name: Prod
steps:
- uses: actions/checkout@v2
with:
submodules: true
- name: Build And Deploy
id: builddeploy
uses: Azure/static-web-apps-deploy@v1
with:
azure_static_web_apps_api_token: ${{ secrets.AZURE_STATIC_WEB_APPS_API_TOKEN_BRAVE_ROCK_0AAC63D03 }}
repo_token: ${{ secrets.GITHUB_TOKEN }} # Used for Github integrations (i.e. PR comments)
action: &amp;#34;upload&amp;#34;
###### Repository/Build Configurations - These values can be configured to match your app requirements. ######
# For more information regarding Static Web App workflow configurations, please visit: https://aka.ms/swaworkflowconfig
app_location: &amp;#34;Blog&amp;#34; # App source code path
api_location: &amp;#34;Blog.Func&amp;#34; # Api source code path - optional
output_location: &amp;#34;wwwroot&amp;#34; # Built app content directory - optional
###### End of Repository/Build Configurations ######
&lt;/code>&lt;/pre>&lt;p>The first thing I did was create three Azure Static Web Apps, I am using the free tier so while this is trippling my costs it is all still free! Doing this created three github action workflow files, I deleted two and edited the third, but before I deleted them I made a note of the AZURE_STATIC_WEB_APPS_API_TOKEN. If you look in your settings -&amp;gt; secrets for your repo you will see secrets have been created, this is the secure token that github uses to update your static web app.&lt;/p>
&lt;p>While we are in settings we might as well look at environments. I created a Prod, Test and Dev environment that I was going to use in my github actions.&lt;/p>
&lt;p>Environments can have various rules setup on them.&lt;/p>
&lt;ul>
&lt;li>Required reviewers - this is like an approver, a user specified here must aprove for the workflow to be deployed&lt;/li>
&lt;li>Wait time - I didn&amp;rsquo;t use this, but it looks like a certain amount of time can be set to pause the deployment. (I assume to do some kind of manual check)&lt;/li>
&lt;li>Deployment Branch - specify what branch are allowed to be deployed to what environments. I specified develop, main and feature branches could be deployed to the Dev environment, develop and main could go on Test and main could go on Prod&lt;/li>
&lt;li>Environment secrets - I didn&amp;rsquo;t use this as my secrets were already created, however it looks like your secrets can be associated with a specific environment&lt;/li>
&lt;/ul>
&lt;p>Now that we have the static web apps setup and the environments lets look at the github action file.&lt;/p>
&lt;p>First of all I removed the PR stuff and just concentrated on pushes. I wanted my workflow to be.&lt;/p>
&lt;ol>
&lt;li>Push to feature branch&lt;/li>
&lt;li>Deploys to Dev env&lt;/li>
&lt;li>PR feature branch to develop&lt;/li>
&lt;li>Once merged code gets pushed into develop&lt;/li>
&lt;li>Deploys to Test env&lt;/li>
&lt;li>PR develop to main&lt;/li>
&lt;li>Once merged code gets pushed into main&lt;/li>
&lt;li>Deploys to Prod env (after approval)&lt;/li>
&lt;/ol>
&lt;p>The approval on deploying to production I think is probably overkill, but I still have it setup like that for now.&lt;/p>
&lt;p>My gh action has three jobs defined as dev: test: and prod: they are all the same except they have the azure_static_web_apps_api_token that is correct for their environment.&lt;/p>
&lt;p>They also each have a environment defined eg&lt;/p>
&lt;pre tabindex="0">&lt;code>environment:
name: Prod
&lt;/code>&lt;/pre>&lt;p>Lastly Test and Prod have an if test setup, if the test is false the job won&amp;rsquo;t run. Importantly it won&amp;rsquo;t fail it just won&amp;rsquo;t run.&lt;/p>
&lt;p>For Prod this needs to only run on main branch so we have&lt;/p>
&lt;p>if: github.ref == &amp;lsquo;refs/heads/main&amp;rsquo;&lt;/p>
&lt;p>For Test this needs to only run on develop so&lt;/p>
&lt;p>if: github.ref == &amp;lsquo;refs/heads/develop&amp;rsquo;&lt;/p>
&lt;p>I could have a test for develop to only run on feature/* but I have allowed it to run everytime.&lt;/p>
&lt;p>There is loads more you can do with github actions, but hopefully this gives you a taste of some of the things you can do. I currently have a mix of Azure DevOps and github actions so I will be working on getting github actions to do more.&lt;/p></description></item><item><title>Azure DevOps Release Pipelines Pre and Post Approval</title><link>https://www.funkysi1701.com/posts/2021/azure-devops-release-pipelines-pre-and-post-approval/</link><pubDate>Sun, 14 Feb 2021 20:00:45 +0000</pubDate><guid>https://www.funkysi1701.com/posts/2021/azure-devops-release-pipelines-pre-and-post-approval/</guid><description>&lt;p>Azure DevOps release pipelines have lots of options to do things how you want. One of my favourites is the option for approval.&lt;/p>
&lt;p>There are two ways you can do approvals Pre and Post deployment. Lets look at both.&lt;/p>
&lt;h2 id="pre-deployment-approval">Pre Deployment Approval&lt;a class="anchor ms-1" href="#pre-deployment-approval">&lt;i class="fas fa-link">&lt;/i>&lt;/a>&lt;/h2>
&lt;p>&lt;img class="img-fluid" alt="image" src="https://dev-to-uploads.s3.amazonaws.com/i/9k6vo6pfv434u7yq3mt4.png" loading="lazy"
/>
&lt;/p>
&lt;p>Lets imagine you have a simple deployment pipeline that deploys to a test/development environment before deploying to a production environment.&lt;/p>
&lt;p>Pre Deployment Approval happens immediately before the release so in this example, click in the ellipse before the Prod release step.&lt;/p>
&lt;p>You will get a screen like the above, you can select what users need to approve it and how long approval waits before timing out, the default is 30 days, but I tend to use a shorter time out of 3 days.&lt;/p>
&lt;h2 id="post-deployment-approval">Post Deployment Approval&lt;a class="anchor ms-1" href="#post-deployment-approval">&lt;i class="fas fa-link">&lt;/i>&lt;/a>&lt;/h2>
&lt;p>&lt;img class="img-fluid" alt="image" src="https://dev-to-uploads.s3.amazonaws.com/i/reiulrhinzqyyon6mrqi.png" loading="lazy"
/>
&lt;/p>
&lt;p>Post Deployment Approval happens immediately after the release so in this example, click in the circle after the Test release step.&lt;/p>
&lt;p>You will get a screen like the above, with the same settings as before.&lt;/p>
&lt;p>That is pretty much all there is to approvals so either option will prompt you to approve before anything gets deployed to your production environment.&lt;/p>
&lt;h2 id="deployment-hours">Deployment Hours&lt;a class="anchor ms-1" href="#deployment-hours">&lt;i class="fas fa-link">&lt;/i>&lt;/a>&lt;/h2>
&lt;p>To complicate matters I make use of the following setting to define deployment hours.
&lt;img class="img-fluid" alt="image" src="https://dev-to-uploads.s3.amazonaws.com/i/aku2z0dl3m3xkvfvh7wd.png" loading="lazy"
/>
&lt;/p>
&lt;p>This setting will start the Prod deployment at 3am Mon-Fri.&lt;/p>
&lt;p>If I configure Post Deployment Approval, as soon as my deploy to Test has completed a request for Approval is sent.&lt;/p>
&lt;p>If I configure Pre Deployment Approval, at 3am Mon-Fri a request for Approval is sent (not ideal if you tend to be asleep at 3am)&lt;/p>
&lt;p>So it looks like Post Deployment Approval is more useful for my use case. However if you deny approval either in Pre or Post approval this will mark the deployment as failed and show Red in your list of deployments.&lt;/p>
&lt;p>&lt;img class="img-fluid" alt="image" src="https://dev-to-uploads.s3.amazonaws.com/i/vichyb1srgc1ln85hj0o.png" loading="lazy"
/>
&lt;/p>
&lt;p>From a casual glance it looks like the deployment to Test is failing, it isn&amp;rsquo;t I am just opting to not continue my deployment to production.&lt;/p>
&lt;h2 id="my-pipeline">My Pipeline&lt;a class="anchor ms-1" href="#my-pipeline">&lt;i class="fas fa-link">&lt;/i>&lt;/a>&lt;/h2>
&lt;p>&lt;img class="img-fluid" alt="image" src="https://dev-to-uploads.s3.amazonaws.com/i/9kprp90t59owfmsmqkcp.png" loading="lazy"
/>
&lt;/p>
&lt;p>This is how I have my pipeline setup. Deployment happens on Test and doesn&amp;rsquo;t have a post approval step.&lt;/p>
&lt;p>After Test an empty stage called Approval runs and that has a post deployment approval, this happens immediately after Test so you get asked straight away for approval.&lt;/p>
&lt;p>Prod does not start as I have my deployment hours configured. Once it is time for deployment to Prod to start it executes.&lt;/p>
&lt;p>Now a casual look at my past releases, you can easily see which have been stopped by approval and which have failed due to whatever issue, and which have run all the way through to Prod.&lt;/p>
&lt;p>And deployments to Prod can only ever run during my defined deployment window.&lt;/p>
&lt;p>I am interested to hear how you have your deployment pipeline setup. Do you make use of Pre or Post Approvals? Do you ensure deployments always happen at specific times?&lt;/p></description></item><item><title>Gated Release</title><link>https://www.funkysi1701.com/posts/2019/gated-release/</link><pubDate>Fri, 05 Apr 2019 20:00:45 +0000</pubDate><guid>https://www.funkysi1701.com/posts/2019/gated-release/</guid><description>&lt;p>Automated releases of software are great but how can we add an element of feedback so only good releases go live.&lt;/p>
&lt;p>I have been using Azure DevOps to release my &lt;a href="https://www.funkysi1701.com/pwned-pass/">PwnedPass&lt;/a>
android app to the Google Play Store for a while now. There are options to deploy to the alpha, Beta or Production tracks and even to set % of users to target. For the full range of options check out the Google Play &lt;a href="https://marketplace.visualstudio.com/items?itemName=ms-vsclient.google-play" target="_blank" rel="noopener noreferrer">extension&lt;/a>
for Azure DevOps.&lt;/p>
&lt;p>My release starts by publishing to 10% of users on the production track, my next step makes use of the increase rollout option to increase this %, you can have as many of these additional steps as you want until you reach 100% of your users.&lt;/p>
&lt;p>&lt;img class="img-fluid" alt="Image" src="https://storageaccountblog9f5d.blob.core.windows.net/blazor/wp-content/uploads/2019/04/image.png?fit=662%2C116&amp;amp;ssl=1" loading="lazy"
/>
&lt;/p>
&lt;p>Now if you run this release now it will just run through each of the steps one after the other. Now of course you can add a pre or post approval to your pipeline but this just adds a manual dependency to your release. Whoever does the approving needs to check things are working before approving or worse just approves regardless.&lt;/p>
&lt;p>Azure DevOps has the concept of &lt;a href="https://docs.microsoft.com/en-us/azure/devops/pipelines/release/deploy-using-approvals?view=azure-devops" target="_blank" rel="noopener noreferrer">gated releases&lt;/a>
which allows you to add automated checks before or after a release happens. These automated checks can be any of the following:&lt;/p>
&lt;ul>
&lt;li>An Azure Function&lt;/li>
&lt;li>A Rest API call&lt;/li>
&lt;li>Azure Monitor Alert&lt;/li>
&lt;li>Query Work Items&lt;/li>
&lt;li>Security and Compliance Assessment&lt;/li>
&lt;/ul>
&lt;p>We are going to make use of the Azure Monitor Alert, to create an alert from your Application Insights data and only continue the rollout if no failures are detected.&lt;/p>
&lt;p>Open up your application insights resource in the Azure portal and look in alerts. Click add new alert rule.&lt;/p>
&lt;p>&lt;img class="img-fluid" alt="Image" src="https://storageaccountblog9f5d.blob.core.windows.net/blazor/wp-content/uploads/2019/04/image-1.png?fit=662%2C552&amp;amp;ssl=1" loading="lazy"
/>
&lt;/p>
&lt;p>Select your application insights resource in Resource, In Condition choose a condition to check, I chose Failed Requests, so every time a failure is registered in my API I can stop the deployment. The exact criteria you want to use is entirely up to you.&lt;/p>
&lt;p>Create an action group, I just set my alert to send an email to myself but there are other alert actions you may want to try. Give your alert a name and description and click save.&lt;/p>
&lt;p>Now all we need to do is make Azure DevOps make use of this alert. In your release pipeline select the pre-deployment conditions of your second step and open up the Gates section.&lt;/p>
&lt;p>&lt;img class="img-fluid" alt="Image" src="https://storageaccountblog9f5d.blob.core.windows.net/blazor/wp-content/uploads/2019/04/image-2.png?fit=662%2C498&amp;amp;ssl=1" loading="lazy"
/>
&lt;/p>
&lt;p>Choose a suitable time to evaluate, I have been using something long like 12 or 24 hours so if there are problems there is time for it to be noticed. Choose Version 1 of the task (I was not able to get it to work with Version 0)&lt;/p>
&lt;p>Now select your Azure subscription and Resource Group and leave the rest of the settings as they are. Now your Deployment will stop and analyse application insights for any Failed requests and will halt if it finds any.&lt;/p>
&lt;p>&lt;img class="img-fluid" alt="Image" src="https://storageaccountblog9f5d.blob.core.windows.net/blazor/wp-content/uploads/2019/04/image-3.png?fit=662%2C88&amp;amp;ssl=1" loading="lazy"
/>
&lt;/p>
&lt;p>I am still testing this out but it will take a few days to figure out if this what I want due to the large time scales involved. I feel this is going to be an improvement of manually approving release steps.&lt;/p></description></item><item><title>Microsoft Ignite | The Tour – London</title><link>https://www.funkysi1701.com/posts/2019/microsoft-ignite-the-tour-london/</link><pubDate>Tue, 26 Feb 2019 20:00:45 +0000</pubDate><guid>https://www.funkysi1701.com/posts/2019/microsoft-ignite-the-tour-london/</guid><description>&lt;p>I have just spent the first day at the conference Microsoft Ignite | The Tour.
&lt;img class="img-fluid" alt="Alt Text" src="https://storageaccountblog9f5d.blob.core.windows.net/blazor/wp-content/uploads/2019/02/D0UTj08XgAEo1YJ.jpg?fit=662%2C440&amp;amp;ssl=1" loading="lazy"
/>
The conference was free I just needed to arrange travel and accommodation. Microsoft have really looked after me and all the other guests, breakfast and lunch has been provided, I got a free t-shirt, coffee (or tea) all day plus a beer or glass of wine to end the day. And that’s before you collect any free stuff the vendors are giving away.&lt;/p>
&lt;p>The first session was Designing resilient cloud applications with &lt;a href="https://twitter.com/CodeMillMatt" target="_blank" rel="noopener noreferrer">Matt Soucoup&lt;/a>
and talked about some cloud technologies like Azure key vault and serving static files from blob storage. Unfortunately this had a few technical issues with the demos. I think it was just connectivity with the MongoDB backend but this slightly spoiled the session. As this was the only technical problem I noticed all day I can let it pass.&lt;/p>
&lt;p>Next was a session on Azure DevOps mainly build and release pipelines called Deploying your application faster and safer with &lt;a href="https://twitter.com/bbenz" target="_blank" rel="noopener noreferrer">Brian Benz&lt;/a>
. A lot of this I knew but good to reinforce I am doing things correctly.&lt;/p>
&lt;p>Next was a session on Application Insights called Detecting application anomalies with Telemetry with Matt Soucoup.&lt;/p>
&lt;p>Probably the most useful session was on Docker and Kubernetes called Integrate containers and Kubernetes into your Azure DevOps build and release model with &lt;a href="https://twitter.com/crad77" target="_blank" rel="noopener noreferrer">Marco De Sanctis&lt;/a>
. Going to spend some time looking through the examples from this session.&lt;/p>
&lt;p>A session on Serverless covered Azure Functions, Azure Logic apps and the other Azure Serverless offerings. Investing in Serverless: less servers, more code with &lt;a href="https://twitter.com/simona_cotin" target="_blank" rel="noopener noreferrer">Simona Cotin&lt;/a>
.&lt;/p>
&lt;p>Lastly was a panel discussion on the changes facing IT Pros and SysAdmins. What is the future of the IT Pro in a DevOps &amp;amp; Cloudy world? with &lt;a href="https://twitter.com/jenstirrup" target="_blank" rel="noopener noreferrer">Jennifer Stirrup&lt;/a>
, &lt;a href="https://twitter.com/bakionur" target="_blank" rel="noopener noreferrer">Baki Onur Okutucu&lt;/a>
, &lt;a href="https://twitter.com/AmyKateNicho" target="_blank" rel="noopener noreferrer">Amy Boyd&lt;/a>
and &lt;a href="https://twitter.com/TheOpsMgr" target="_blank" rel="noopener noreferrer">Stephen Thair&lt;/a>
. Should they learn to code, how should they make sure they keep up.&lt;/p>
&lt;p>Tomorrow I have a loads more sessions, including ones about mental health, Azure pipelines, more Kubernetes stuff and dealing with failure.&lt;/p></description></item><item><title>Yaml Builds on Azure DevOps</title><link>https://www.funkysi1701.com/posts/2019/yaml-builds-on-azure-devops/</link><pubDate>Thu, 31 Jan 2019 20:00:45 +0000</pubDate><guid>https://www.funkysi1701.com/posts/2019/yaml-builds-on-azure-devops/</guid><description>&lt;p>I have been using Azure DevOps (Or VSTS or VSO etc) for a while now and one of the great features is doing automatic builds with every check-in. This is more commonly known as a CI (continuous integration) build.&lt;/p>
&lt;p>More recently I have started playing about with creating my build using YAML files instead of using the web user interface to create my build.&lt;/p>
&lt;h2 id="why">Why?&lt;a class="anchor ms-1" href="#why">&lt;i class="fas fa-link">&lt;/i>&lt;/a>&lt;/h2>
&lt;p>You may wonder why go to the effort of learning the YAML syntax when you can just create the build in Azure DevOps and then forget about it.&lt;/p>
&lt;p>Mostly it is because the build changes over time and you shouldn’t just forget about it. If something changes over time then you might want to version control it, or look at a previous version.&lt;/p>
&lt;p>Lets say you create a pull request that replaces a .net 4.7 web service with a .net core web service. If you have a CI build this PR will fail because it won’t build. If you change the build first any other builds going on will fail. What you want in this case is the build to be associated with that branch or PR. Any builds before you merge this change in will continue to work and any after this change will also work.&lt;/p>
&lt;h2 id="how">How?&lt;a class="anchor ms-1" href="#how">&lt;i class="fas fa-link">&lt;/i>&lt;/a>&lt;/h2>
&lt;p>How do you get started with YAML builds? Well the first thing is to make sure that YAML builds are turned on, as I write this I believe they are still a feature you can turn on or off. Have a look in Preview features and make sure they are turned on.&lt;/p>
&lt;p>Next look at any of your existing builds and click the View YAML link. This will show you an example YAML file of your existing build. You could just save this as azure-pipelines.yml and checkin to the root of your project. You can also click the add new build pipeline option, this will give you some templates to start you off.&lt;/p>
&lt;p>The YAML file consists of a series of build steps usually called tasks, with a few settings before to configure things like parameters or build agents. Detailed docs about the syntax of the file can be found &lt;a href="https://docs.microsoft.com/en-us/azure/devops/pipelines/yaml-schema?view=azure-devops&amp;amp;tabs=schema" target="_blank" rel="noopener noreferrer">here&lt;/a>
.&lt;/p>
&lt;p>For my mobile app my YAML files consist of downloading nuget packages, building the solution, building specific projects with desired settings, running powershell or other scripts to set things up and finally publishing the results of the build as artifacts so that they can be used in any releases.&lt;/p>
&lt;h2 id="secure-it">Secure It!&lt;a class="anchor ms-1" href="#secure-it">&lt;i class="fas fa-link">&lt;/i>&lt;/a>&lt;/h2>
&lt;p>Avoid committing passwords and secure keys into source control. I have found you can upload secure files via Azure DevOps and then add a download secure files step at the start of your build. This allows the secure file to be used during the build but the contents of the file can’t be viewed by anyone with access to the source code.&lt;/p>
&lt;p>I find it often takes a bit of thinking about how to achieve this, but it is usually possible to keep keys and secrets secure.&lt;/p></description></item><item><title>Let’s Encrypt is awesome</title><link>https://www.funkysi1701.com/posts/2018/lets-encrypt-is-awesome/</link><pubDate>Mon, 30 Apr 2018 00:00:00 +0000</pubDate><guid>https://www.funkysi1701.com/posts/2018/lets-encrypt-is-awesome/</guid><description>&lt;p>Let’s Encrypt is a free way to get a SSL certificate onto your website and until recently I had never tried it. It is very easy and I think it is awesome.&lt;/p>
&lt;p>IIS is the web server software the Microsoft include with Windows 10 and Windows Server. I have it installed on my laptop and it displays the default IIS page.&lt;/p>
&lt;p>&lt;img class="img-fluid" alt="" src="https://storageaccountblog9f5d.blob.core.windows.net/blazor/wp-content/uploads/2018/04/iis.jpg?resize=768%2C464&amp;amp;ssl=1" loading="lazy"
/>
&lt;/p>
&lt;p>It is not really a good idea to host websites on your laptop, use a dedicated web server, or host with a hosting company, however the techniques are the same and it gives me something to write about!&lt;/p>
&lt;p>In order to point a domain name at what IIS on my machine was serving up I did the following:&lt;/p>
&lt;ul>
&lt;li>Do a google search for “whats my IP”, this will return your public IP. Most residential ISPs use dynamic IPs so it may change over time, (which is another reason not to host a website on your laptop!)&lt;/li>
&lt;li>Add an A record on a domain with the IP address you have just got&lt;/li>
&lt;li>Your public IP most likely points at your router not your laptop so enable port forwarding of port 80 and port 443 to the internal IP of your laptop (something like 192.168.0.11 etc)&lt;/li>
&lt;/ul>
&lt;p>Now comes the fun Let’s Encrypt stuff!&lt;/p>
&lt;p>First you need a Let’s Encrypt client, there are a lot of them out there mostly for linux flavours, however a bit of googling found a windows one. Go to &lt;a href="https://github.com/PKISharp/win-acme/releases" target="_blank" rel="noopener noreferrer">https://github.com/PKISharp/win-acme/releases&lt;/a>
and download the zip file and unzip it.&lt;/p>
&lt;p>Run the executable from the zip file and follow the onscreen prompts.&lt;/p>
&lt;p>&lt;img class="img-fluid" alt="" src="https://storageaccountblog9f5d.blob.core.windows.net/blazor/wp-content/uploads/2018/04/letsencrypt.jpg?resize=768%2C480&amp;amp;ssl=1" loading="lazy"
/>
&lt;/p>
&lt;p>Press N to create a new certificate.&lt;/p>
&lt;p>Then press 1 to bind to single website found in your IIS setup&lt;/p>
&lt;p>&lt;img class="img-fluid" alt="" src="https://storageaccountblog9f5d.blob.core.windows.net/blazor/wp-content/uploads/2018/04/letsencrypt2.jpg?resize=768%2C686&amp;amp;ssl=1" loading="lazy"
/>
&lt;/p>
&lt;p>And now magically Let’s Encrypt knows what you have setup in IIS.&lt;/p>
&lt;p>Now all you need to do is enter an email address incase a renewal fails and agree to the let’s encrypt terms and you are all setup.&lt;/p>
&lt;p>&lt;img class="img-fluid" alt="" src="https://storageaccountblog9f5d.blob.core.windows.net/blazor/wp-content/uploads/2018/04/letsencrypt3.jpg?resize=768%2C920&amp;amp;ssl=1" loading="lazy"
/>
&lt;/p>
&lt;p>How awesome and easy is that for getting your websites working with a SSL certificate. If you have IIS configured on a server, give it a try and you can SSL all your things.&lt;/p></description></item><item><title>DNS for Developers</title><link>https://www.funkysi1701.com/posts/2018/dns-for-developers/</link><pubDate>Mon, 09 Apr 2018 00:00:00 +0000</pubDate><guid>https://www.funkysi1701.com/posts/2018/dns-for-developers/</guid><description>&lt;p>DNS is the backbone of the internet and as such I believe every developer should know something about the basics and not just leave it for the sysadmin to sort.&lt;/p>
&lt;h3 id="what-is-dns">What is DNS?&lt;a class="anchor ms-1" href="#what-is-dns">&lt;i class="fas fa-link">&lt;/i>&lt;/a>&lt;/h3>
&lt;p>DNS or Domain Name System is what translates Domain names to IP addresses and vice versa.&lt;/p>
&lt;h3 id="wait-what-is-an-ip-address-and-what-are-domain-names">Wait what is an IP address and what are domain names?&lt;a class="anchor ms-1" href="#wait-what-is-an-ip-address-and-what-are-domain-names">&lt;i class="fas fa-link">&lt;/i>&lt;/a>&lt;/h3>
&lt;p>You do realise this is a developer blog? An IP address is a unique address on the internet and a domain name is a user friendly label for one or more of these.&lt;/p>
&lt;p>An example might be google.com which for me resolves to 216.58.204.14&lt;/p>
&lt;h3 id="how-it-works">How it works&lt;a class="anchor ms-1" href="#how-it-works">&lt;i class="fas fa-link">&lt;/i>&lt;/a>&lt;/h3>
&lt;p>&lt;img class="img-fluid" alt="" src="https://storageaccountblog9f5d.blob.core.windows.net/blazor/wp-content/uploads/2018/04/dns-rev-1.gif?resize=360%2C320&amp;amp;ssl=1" loading="lazy"
/>
When your browser makes a request to google.com it makes a request to your ISPs DNS Servers. This resolves google.com to 216.58.204.14&lt;/p>
&lt;p>In more detail your ISPs DNS server will forward the DNS query to another DNS server and will cache the results for a set amount of time. This is the TTL or Time To Live. Next time the ISP DNS Server will be able to reply directly without needing to forward requests.&lt;/p>
&lt;p>This forwarding and caching is what makes making a DNS change not instantaneous. The TTL needs to be reached so that no results are still being fetched from the cache of DNS servers across the globe.&lt;/p>
&lt;h3 id="dns-records">DNS Records&lt;a class="anchor ms-1" href="#dns-records">&lt;i class="fas fa-link">&lt;/i>&lt;/a>&lt;/h3>
&lt;p>Now we know roughly how DNS works let’s look at the most common type of records&lt;/p>
&lt;h4 id="a">A&lt;a class="anchor ms-1" href="#a">&lt;i class="fas fa-link">&lt;/i>&lt;/a>&lt;/h4>
&lt;p>A (Host) records are the most simple records which translate domain names to IPs&lt;/p>
&lt;p>eg &lt;a href="https://www.google.com" target="_blank" rel="noopener noreferrer">www.google.com&lt;/a>
to 216.58.204.14&lt;/p>
&lt;h4 id="cname">CNAME&lt;a class="anchor ms-1" href="#cname">&lt;i class="fas fa-link">&lt;/i>&lt;/a>&lt;/h4>
&lt;p>A CNAME (Canonical Name) record is different to an A record in that it maps a domain name to another domain name when no A record exists.&lt;/p>
&lt;p>eg &lt;a href="https://www.google.com" target="_blank" rel="noopener noreferrer">www.google.com&lt;/a>
to somethingelse.google.com&lt;/p>
&lt;p>Typically Azure makes use of CNAMEs for many of its services especially adding a custom domain name&lt;/p>
&lt;h4 id="mx">MX&lt;a class="anchor ms-1" href="#mx">&lt;i class="fas fa-link">&lt;/i>&lt;/a>&lt;/h4>
&lt;p>MX stands for Mail Exchange and is used for configuring email&lt;/p>
&lt;h4 id="name-server">Name Server&lt;a class="anchor ms-1" href="#name-server">&lt;i class="fas fa-link">&lt;/i>&lt;/a>&lt;/h4>
&lt;p>Every domain has a number of Name Servers which tells you what servers control the DNS settings for that domain. If you change your Name Servers then the new Name servers will be where you can change your DNS settings.&lt;/p>
&lt;p>If you want to use a service like &lt;a href="https://dnsimple.com/" target="_blank" rel="noopener noreferrer">DNSimple&lt;/a>
instead of &lt;a href="https://www.123-reg.co.uk/" target="_blank" rel="noopener noreferrer">123reg&lt;/a>
or where ever you registered your domain then all you need to do is change your Name servers.&lt;/p>
&lt;h4 id="aaaa">AAAA&lt;a class="anchor ms-1" href="#aaaa">&lt;i class="fas fa-link">&lt;/i>&lt;/a>&lt;/h4>
&lt;p>Like A record but for ipv6&lt;/p>
&lt;h3 id="what-next">What next?&lt;a class="anchor ms-1" href="#what-next">&lt;i class="fas fa-link">&lt;/i>&lt;/a>&lt;/h3>
&lt;p>Want to put some different DNS records into practise? Buy a domain name and publish some content to it. Check out my previous post about &lt;a href="https://www.funkysi1701.com/creating-dns-records-programmatically">programmatically adding records&lt;/a>
. Want an SSL certificate? Get a wildcard one and then you can apply it to any subdomain you add to your domain.&lt;/p>
&lt;p>If you have a new website you want to publish consider which of the following is better:&lt;/p>
&lt;p>&lt;a href="https://www.example.com/newsite" target="_blank" rel="noopener noreferrer">https://www.example.com/newsite&lt;/a>
&lt;/p>
&lt;p>&lt;a href="https://newsite.example.com" target="_blank" rel="noopener noreferrer">https://newsite.example.com&lt;/a>
&lt;/p>
&lt;p>I much prefer the second option, it looks cleaner, there is no potential conflict with the parent site, no subfolder issues between production and development.&lt;/p></description></item><item><title>Chrome distrusts SSL Certificates</title><link>https://www.funkysi1701.com/posts/2018/ssl-distrusts/</link><pubDate>Mon, 19 Feb 2018 00:00:00 +0000</pubDate><guid>https://www.funkysi1701.com/posts/2018/ssl-distrusts/</guid><description>&lt;p>One of the websites I have been working on has been displaying an error in the console. The error reads as follows.&lt;/p>
&lt;pre tabindex="0">&lt;code>The SSL certificate used to load resources from https://example.com will be distrusted in M70. Once distrusted, users will be prevented from loading these resources. See https://g.co/chrome/symantecpkicerts for more information.
&lt;/code>&lt;/pre>&lt;p>But what does this mean? Well let’s start by looking at the &lt;a href="https://security.googleblog.com/2017/09/chromes-plan-to-distrust-symantec.html" target="_blank" rel="noopener noreferrer">link&lt;/a>
provided.&lt;/p>
&lt;p>In January 2017 it was revealed that Certificate Authorities run by Symantec which include Thawte, VeriSign, Equifax, GeoTrust, and RapidSSL had been issuing certificates that did not comply with baseline standards.&lt;/p>
&lt;p>Starting with Chrome 66, Google has decided to remove trust for these certificates. Chrome 66 is due for release around 17th April. My error mentions M70 so what does that refer to?&lt;/p>
&lt;p>Chrome 70 which is due to be released in October 2018 will removed the trust for another batch of Symantec certificates.&lt;/p>
&lt;p>If you are getting one of these errors because you are using a certificate that is going to be distrusted what will your site look like in Chrome 66 or Chrome 70?&lt;/p>
&lt;p>Well Chrome 66 is now in the dev channel so we can give it a try. &lt;img class="img-fluid" alt="" src="https://storageaccountblog9f5d.blob.core.windows.net/blazor/wp-content/uploads/2018/02/tempsnip.png.jpg?resize=662%2C443&amp;amp;ssl=1" loading="lazy"
/>
&lt;/p>
&lt;p>Not very nice for your users is it? Now is the time to order a new SSL certificate to avoid this happening to your site.&lt;/p>
&lt;p>I first saw this error a few months ago and have been reading up about it and waiting for Chrome 66 to reach the dev channel so I could test what it did to my site. However now that I have Chrome 66 installed I spotted the intranet for the company I work for is also affected. I do not directly work on the intranet so I notified the security team that they may want to look into this.&lt;/p>
&lt;p>Unfortunately the response I received has been that Google needs to fix this before Chrome 66 is released. I am not criticising my employer or the security team, however this isn’t something Google can just “ &lt;strong>fix&lt;/strong> “.&lt;/p>
&lt;p>The certificates issued were issued by a CA that had issues so in order to maintain the trustworthiness of all certificates Google had little choice but to distrust them. Google and security experts need to be making more of a fuss about this and I am joining in on making a fuss by writing this blog. &lt;a href="https://scotthelme.co.uk/are-you-ready-for-the-symantec-distrust/" target="_blank" rel="noopener noreferrer">Scott Helme&lt;/a>
estimates that there are about 7000 websites which may be affected by the M66 and M70 distrusts.&lt;/p></description></item><item><title>Moving files into blob storage</title><link>https://www.funkysi1701.com/posts/2018/moving-blobs-cloud-suppliers/</link><pubDate>Mon, 22 Jan 2018 00:00:00 +0000</pubDate><guid>https://www.funkysi1701.com/posts/2018/moving-blobs-cloud-suppliers/</guid><description>&lt;p>We are in the process of moving our companies websites onto the Azure platform. One of the challenges was to move image files out of the website project into blob storage. This week I have moved 150,000 of them.&lt;/p>
&lt;p>One thing I keep banging on about is that your source code should not contain data. If it does every time you do a deployment you need to consider where these images are located and ensure you don’t overwrite or loose any. It also goes without saying that deployments of a few Mb are a lot quicker than deployments of 100s of Mb.&lt;/p>
&lt;p>Azure blob storage also gives you advantages like distributing storage across multiple datacenters which would be impossible with traditional files on a server.&lt;/p>
&lt;p>So now that we have established that this is a good idea lets look at how we could move large amounts of data. In my case all the filenames are stored in a SQL database so the plan of action was to simply loop through the files in the database, download from current storage (either locally or other cloud storage), upload to Azure and tidy up afterwards. Due to the number of images I am going to update the database and mark when a file has been processed so I can do the move over several days.&lt;/p>
&lt;p>This is my code&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> source = &lt;span style="color:#e6db74">&amp;#34;https://example.com/images/&amp;#34;&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> tmp = Server.MapPath(&lt;span style="color:#e6db74">&amp;#34;~/tmp/&amp;#34;&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">if&lt;/span> (!Directory.Exists(tmp))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Directory.CreateDirectory(tmp);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> fixturePhotos = db.Images.Where(x =&amp;gt; x.Moved == &lt;span style="color:#66d9ef">null&lt;/span> || x.Moved == &lt;span style="color:#ae81ff">0&lt;/span>).Take(id);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">foreach&lt;/span> (&lt;span style="color:#66d9ef">var&lt;/span> photo &lt;span style="color:#66d9ef">in&lt;/span> fixturePhotos)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">try&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">string&lt;/span> path = getFilePath(photo.FileName);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> (!Directory.Exists(Server.MapPath(&lt;span style="color:#e6db74">&amp;#34;~/tmp/&amp;#34;&lt;/span> + path)))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Directory.CreateDirectory(Server.MapPath(&lt;span style="color:#e6db74">&amp;#34;~/tmp/&amp;#34;&lt;/span> + path));
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> WebClient WebClient = &lt;span style="color:#66d9ef">new&lt;/span> WebClient();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> WebClient.DownloadFile(source + photo.FileName, tmp + photo.FileName);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> FileUploader f = &lt;span style="color:#66d9ef">new&lt;/span> FileUploader(tmp + photo.FileName, photo.FileName);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> System.IO.File.Delete(tmp + photo.FileName);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> photo.Moved = &lt;span style="color:#ae81ff">1&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">catch&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> photo.Moved = &lt;span style="color:#ae81ff">0&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>db.SaveChanges();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">if&lt;/span> (Directory.Exists(tmp))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Directory.Delete(tmp, &lt;span style="color:#66d9ef">true&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>First of all I create a tmp folder in the root of my website if it doesn’t exist to store my images temporarily.&lt;/p>
&lt;p>I then use an entity framework model to query the database that haven’t been moved, and I use the take() method to limit how many results I process. (I have been passing in 1000 at a time)&lt;/p>
&lt;p>I then use a foreach loop over all these files to perform the following actions.&lt;/p>
&lt;ol>
&lt;li>Create additional subfolders if the filename variable stored in the database isn’t actually a filename but a filepath, note you will have to split filename and filepath which I haven’t included code for here.&lt;/li>
&lt;li>Download file from the original url and save into the temporary folder&lt;/li>
&lt;li>Upload to Azure&lt;/li>
&lt;li>Delete temporary file&lt;/li>
&lt;li>Update database giving a success or fail&lt;/li>
&lt;/ol>
&lt;p>Once the foreach is finished I commit the database changes and delete the temporary folder. I am sure there must be other ways to do this transfer but this was quick and easy to setup and now I have a copy of all the files in Azure storage so I can test out other issues with my website.&lt;/p>
&lt;p>One last tip about how to schedule this code. I called the above code from a MVC controller and then wrote a Azure Function to call this code on a schedule.&lt;/p></description></item><item><title>Azure Functions</title><link>https://www.funkysi1701.com/posts/2017/azure-functions/</link><pubDate>Tue, 12 Sep 2017 20:00:45 +0000</pubDate><guid>https://www.funkysi1701.com/posts/2017/azure-functions/</guid><description>&lt;p>I recently blogged about using &lt;a href="https://www.funkysi1701.com/posts/using-azure-webjobs-to-automate-stuff">Azure Web Jobs&lt;/a>
, Azure Function is another way of doing the same thing, lets look at how they work.&lt;/p>
&lt;p>(Sorry its been a while since I blogged but I suspect an erratic schedule will continue for the next few months.)&lt;/p>
&lt;p>To create an Azure Function go to the Azure portal and click add new and search for &amp;ldquo;Function App&amp;rdquo;&lt;/p>
&lt;p>Give your app a name and select the usual resource group and location settings.&lt;/p>
&lt;p>Now when you open Function Apps you should see your new app.&lt;/p>
&lt;p>I want my Function App to run on a schedule so I clicked the + next to functions and selected TimerTrigger. I am a c# programmer so I selected this option as well.&lt;/p>
&lt;p>Give your function a name and specify using the usual cron notation how often it should run. I want mine to run at 9.30pm each night so use 0 30 21 * * *&lt;/p>
&lt;p>Now comes the code bit. By default you get a window with the following code in it&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">using&lt;/span> System;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">static&lt;/span> &lt;span style="color:#66d9ef">void&lt;/span> Run(TimerInfo myTimer, TraceWriter log)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> log.Info(&lt;span style="color:#e6db74">$&amp;#34;C# Timer trigger function executed at: {DateTime.Now}&amp;#34;&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>It is entirely up to you what you get your function to do. In my case I just wanted to call a URL on a schedule so I created some code that used httpclient.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">using&lt;/span> System;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">using&lt;/span> System.Net.Http;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">public&lt;/span> &lt;span style="color:#66d9ef">static&lt;/span> &lt;span style="color:#66d9ef">async&lt;/span> Task Run(TimerInfo myTimer, TraceWriter log)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> log.Info(&lt;span style="color:#e6db74">$&amp;#34;Buffer 0 function executed at: {DateTime.Now}&amp;#34;&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> HttpClient client = &lt;span style="color:#66d9ef">new&lt;/span> HttpClient();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">var&lt;/span> result = &lt;span style="color:#66d9ef">await&lt;/span> client.GetAsync(&lt;span style="color:#e6db74">&amp;#34;URL&amp;#34;&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">string&lt;/span> resultContent = &lt;span style="color:#66d9ef">await&lt;/span> result.Content.ReadAsStringAsync();
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> log.Info(resultContent);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Once you have created your app and it has run you can use the monitor section to view success and failures.&lt;/p>
&lt;p>There is loads more you can do with Azure Function but this is a good place to start.&lt;/p></description></item><item><title>Azure Traffic Manager</title><link>https://www.funkysi1701.com/posts/2015/azure-traffic-manager/</link><pubDate>Thu, 12 Mar 2015 20:00:45 +0000</pubDate><guid>https://www.funkysi1701.com/posts/2015/azure-traffic-manager/</guid><description>&lt;p>I have spent most of the day tweaking my Azure websites. Lots of fun!&lt;/p>
&lt;p>Last week unfortunately Azure had some problems and many websites that were running in the North Europe data centre were unavailable for several hours. And you guessed it my websites were hosted here.&lt;/p>
&lt;p>All hosting providers are going to have downtime from time to time and this is just something you have to take on the chin. The important thing to do in times like these is communicate with your customers about what is going on and that you are doing everything you can to restore service.&lt;/p>
&lt;p>However Azure has some amazing features that you can configure to help manage when downtime occurs.&lt;/p>
&lt;p>Azure is Microsoft’s global cloud platform. And it really is global, there are data centres in North Europe, West Europe, Brazil, Japan, two more in Asia and five in the US. In the event of problems it is highly unlikely that more than one of these would go down at once. If all of these are unavailable, I expect the planet earth is facing some kind of cataclysmic event and the fact that my website is down is not a priority.&lt;/p>
&lt;p>&lt;a href="https://storageaccountblog9f5d.blob.core.windows.net/blazor/wp-content/uploads/2015/03/IC750592.jpg" target="_blank" rel="noopener noreferrer">&lt;img class="img-fluid" alt="IC750592" src="https://storageaccountblog9f5d.blob.core.windows.net/blazor/wp-content/uploads/2015/03/IC750592.jpg?resize=662%2C347" loading="lazy"
/>
&lt;/a>
To take advantage of these multiple data centres, Azure has something called a Traffic Manager.&lt;/p>
&lt;p>Traffic Manager has various settings but I am using it in failover mode. This means that if one website goes down, the next one is used.&lt;/p>
&lt;p>All you need to do is create a traffic manager, add two or more websites to it (called endpoints) and choose a page that needs to be monitored so Azure knows which websites are up and which are down.&lt;/p>
&lt;p>If you are using SSL or custom domain names, there are a few extra steps you need to do. Your custom domain name needs pointing at the traffic manager, not the individual websites. The websites themselves have three domain names, the traffic manager address, the azure address and the custom domain name. The SSL certificate can then be assigned to each website that you have added to the traffic manager.&lt;/p>
&lt;p>That was easy wasn’t it, and now if a website goes down traffic manager will use the next one. While testing this, the transition to the next website was almost immediate. I did notice that if you had a browser showing the website open during a problem you sometimes got an error page, I think this was probably due to browser caching, reopening a tab or browser fixed this issue.&lt;/p></description></item><item><title>What is the difference between Development and Operations?</title><link>https://www.funkysi1701.com/posts/2014/what-is-the-difference-between-dev-and-ops/</link><pubDate>Sat, 27 Sep 2014 20:00:45 +0000</pubDate><guid>https://www.funkysi1701.com/posts/2014/what-is-the-difference-between-dev-and-ops/</guid><description>&lt;p>I want to learn Development and eventually move into a development role. But what is the difference between development and what I already do?&lt;/p>
&lt;p>Put simply Development or programming is the creation of new programs, websites or databases.&lt;/p>
&lt;p>IT Operations or System Administration is the administration of existing servers, websites or databases.&lt;/p>
&lt;p>I have been doing System Administration since I started my job back in 2006. What you do as part of this role can be very simple like setting up new users or computers to something very complex like upgrading the version of Exchange that the company uses for its emails.&lt;/p>
&lt;p>As part of my role I have done a lot of tasks that could be described as development. I have created databases and built new database structures like tables, views and stored procedures. I have also assisted the development department with testing, setting up visual studio, building websites and databases from code.&lt;/p>
&lt;p>Can I describe myself as a developer? I would say yes, I have done plenty of work that is development work.&lt;/p>
&lt;p>Can I get a job as a developer? Possibly but it would depend on the role. I have many of the skills that developers use, but I have limited knowledge in many areas. What I need to do is concentrate my efforts onto the development work I do and delegate as much administration work as I can so my knowledge can increase.&lt;/p>
&lt;p>A Buzz word in IT at the moment is DevOps. I have lost count of the number of times .NetRocks or RunAsRadio have mentioned it.&lt;/p>
&lt;p>DevOps is the integration of IT Development and Operations, it emphasises the need for the two departments to work closely together to achieve common goals. In big companies the two departments can pull against each other if you are not careful, but in my case as I do both roles, it would be very difficult for the development side of myself to blame the operations side of myself for a problem.&lt;/p>
&lt;p>This I think puts me in a good position, I just need to learn more development and I will make a valuable addition to someone’s development team.&lt;/p></description></item></channel></rss>