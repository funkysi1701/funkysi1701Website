<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>2015-03 on Funky Si's Blog</title><link>https://www.funkysi1701.com/2015/03/</link><description>Recent content in 2015-03 on Funky Si's Blog</description><generator>Hugo -- gohugo.io</generator><language>en-gb</language><lastBuildDate>Mon, 16 Mar 2015 00:00:00 +0000</lastBuildDate><atom:link href="https://www.funkysi1701.com/2015/03/index.xml" rel="self" type="application/rss+xml"/><item><title>Source Control Fail</title><link>https://www.funkysi1701.com/posts/2015/source-control-fail/</link><pubDate>Mon, 16 Mar 2015 00:00:00 +0000</pubDate><guid>https://www.funkysi1701.com/posts/2015/source-control-fail/</guid><description>&lt;p>Every developer uses source control, it is a great tool for keeping track of changes to your code, seeing who has done what.&lt;/p>
&lt;p>However I keep messing up, my use of it. I am fairly disciplined when creating new features, all my changes will get committed to source control and when I am happy I will deploy these changes to the live system. But as soon as there is a bug, especially one where the client is chasing for a fix, I will deploy a fix as soon as humanly possible on to the live system.&lt;/p>
&lt;p>At first glance there is nothing wrong with what I have described but what happens the next time I deploy a new feature. Yes the bug the client was complaining about gets deployed with the new feature as the fix was never committed into source control. The client gets angry as the bug he was screaming about is back again.&lt;/p>
&lt;p>Every change you make to the system &lt;strong>MUST&lt;/strong> be committed to source control. If it isn’t that change will look like it never existed. I have worked with source control for over 5 years why do I keep making this rookie mistake over and over.&lt;/p>
&lt;p>Troy Hunt has a &lt;a href="http://www.troyhunt.com/2011/05/10-commandments-of-good-source-control.html" target="_blank" rel="noopener noreferrer">blog post&lt;/a>
about the 10 commandments of using source control. His number two commandment is “If it’s not in source control, it doesn’t exist” He talks more about code you have written being not saved into source control, but the principal is the same for my example as his.&lt;/p>
&lt;p>There are ways to automatically deploy from source control, however most of the time you don’t want your live database being rebuilt because you fixed a typo. Additional steps will need to be implemented and there is still the chance that you might want to bypass these steps to fix the urgent problem. The only way past this problem is for you and everyone on your team to be disciplined and only ever commit to source control first, and only after that deploy live (either automatically or manually)&lt;/p></description></item><item><title>Azure Traffic Manager</title><link>https://www.funkysi1701.com/posts/2015/azure-traffic-manager/</link><pubDate>Thu, 12 Mar 2015 20:00:45 +0000</pubDate><guid>https://www.funkysi1701.com/posts/2015/azure-traffic-manager/</guid><description>&lt;p>I have spent most of the day tweaking my Azure websites. Lots of fun!&lt;/p>
&lt;p>Last week unfortunately Azure had some problems and many websites that were running in the North Europe data centre were unavailable for several hours. And you guessed it my websites were hosted here.&lt;/p>
&lt;p>All hosting providers are going to have downtime from time to time and this is just something you have to take on the chin. The important thing to do in times like these is communicate with your customers about what is going on and that you are doing everything you can to restore service.&lt;/p>
&lt;p>However Azure has some amazing features that you can configure to help manage when downtime occurs.&lt;/p>
&lt;p>Azure is Microsoft’s global cloud platform. And it really is global, there are data centres in North Europe, West Europe, Brazil, Japan, two more in Asia and five in the US. In the event of problems it is highly unlikely that more than one of these would go down at once. If all of these are unavailable, I expect the planet earth is facing some kind of cataclysmic event and the fact that my website is down is not a priority.&lt;/p>
&lt;p>&lt;a href="https://storageaccountblog9f5d.blob.core.windows.net/blazor/wp-content/uploads/2015/03/IC750592.jpg" target="_blank" rel="noopener noreferrer">&lt;img class="img-fluid" alt="IC750592" src="https://storageaccountblog9f5d.blob.core.windows.net/blazor/wp-content/uploads/2015/03/IC750592.jpg?resize=662%2C347" loading="lazy"
/>
&lt;/a>
To take advantage of these multiple data centres, Azure has something called a Traffic Manager.&lt;/p>
&lt;p>Traffic Manager has various settings but I am using it in failover mode. This means that if one website goes down, the next one is used.&lt;/p>
&lt;p>All you need to do is create a traffic manager, add two or more websites to it (called endpoints) and choose a page that needs to be monitored so Azure knows which websites are up and which are down.&lt;/p>
&lt;p>If you are using SSL or custom domain names, there are a few extra steps you need to do. Your custom domain name needs pointing at the traffic manager, not the individual websites. The websites themselves have three domain names, the traffic manager address, the azure address and the custom domain name. The SSL certificate can then be assigned to each website that you have added to the traffic manager.&lt;/p>
&lt;p>That was easy wasn’t it, and now if a website goes down traffic manager will use the next one. While testing this, the transition to the next website was almost immediate. I did notice that if you had a browser showing the website open during a problem you sometimes got an error page, I think this was probably due to browser caching, reopening a tab or browser fixed this issue.&lt;/p></description></item><item><title>Tidying my desktop</title><link>https://www.funkysi1701.com/posts/2015/tidying-my-desktop/</link><pubDate>Wed, 11 Mar 2015 20:00:45 +0000</pubDate><guid>https://www.funkysi1701.com/posts/2015/tidying-my-desktop/</guid><description>&lt;p>My desktop is always a mess. I constantly download files there and forget all about them.&lt;/p>
&lt;p>Every now and then I copy files into sub directories, so my desktop looks sane for a day or two before it gets out of control again.&lt;/p>
&lt;p>Why don’t I write a script that I can schedule to do this for me. Then my desktop will always be tidy.&lt;/p>
&lt;p>I have written a few simple batch scripts, but of course the best scripting language out there at the moment is PowerShell. Lets use that.&lt;/p>
&lt;p>Windows provides a nice little utility for writing scripts called the Windows PowerShell ISE, so let&amp;rsquo;s start by loading that up.&lt;/p>
&lt;p>PS has lots of help included to help you, just run &lt;strong>Get-Help [name of ps command]&lt;/strong>&lt;/p>
&lt;p>To move files you can use &lt;strong>Move-Item&lt;/strong> which works very similar to copy, specify source and destination. In my case I moved files based on their file extension.&lt;/p>
&lt;p>Move-Item *.pdf folder&lt;/p>
&lt;p>Now all I need to do is schedule this script to run either every day or so, or maybe every time I login or switch my computer on.&lt;/p>
&lt;p>PowerShell can do lots more interesting things which hopefully I will blog about soon.&lt;/p></description></item></channel></rss>